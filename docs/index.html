<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Convolutional Implicit Neural Representation of pathology whole-slide images">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Convolutional Implicit Neural Representation of pathology whole-slide images</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">CINR</h1>
          <h1 class="title is-1 publication-title">Convolutional Implicit Neural Representation of pathology whole-slide images</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              DongEon Lee<sup>1</sup>,</span>
            <span class="author-block">
              Chunsu Park<sup>2</sup>,</span>
            <span class="author-block">
              SeonYeong Lee<sup>1</sup>,</span>
            <span class="author-block">
              SiYeoul Lee<sup>1</sup>,</span>
            <span class="author-block">
              MinWoo Kim<sup>2,3</sup>
            </span>
            
            
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Department of Information Convergence Engineering, College of Information and
              Biomedical Convergence Engineering, Pusan National University, Yangsan, Korea,</span>
            <span class="author-block"><sup>2</sup>School of Biomedical Convergence Engineering, College of Information and
              Biomedical Engineering, Pusan National University, Yangsan, Korea</span>
            <span class="author-block"><sup>3</sup>Center for Artificial Intelligence Research, Pusan National University, Busan, Korea</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://doi.org/10.1007/978-3-031-72104-5_19"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/pnu-amilab/CINR"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link.
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div> -->

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="section">
  <div class=" is-max-desktop">
    <!-- Abstract. -->
    <div class=" is-centered has-text-centered">
      <div class=" is-four-fifths">
        <h2 class="title is-3">Differences between original and reconstructed images</h2>
        <img src="./static/images/fig4-1.png">
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>
<hr>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This study explored the application of implicit neural representations (INRs) to enhance digital histopathological imaging. 
          </p>
          <p>
            Traditional imaging methods rely on discretizing the image space into grids, managed through a pyramid file structure to accommodate the large size of whole slide images (WSIs); however, the continuous mapping capability of INRs, utilizing a multi-layer perceptron (MLP) to encode images directly from coordinates, presents a transformative approach. This method promises to streamline WSI management by eliminating the need for down-sampled versions, allowing instantaneous access to any image region at the desired magnification, thereby optimizing memory usage and reducing data storage requirements. 
          </p>
          <p>
            Despite their potential, INRs face challenges in accurately representing high spatial frequency components that are pivotal in histopathology. To address this gap, we introduce a novel INR framework that integrates  auxiliary convolutional neural networks (CNN) with a standard MLP model. 
          </p>
          <p>
            This dual-network approach not only facilitates pixel-level analysis, but also enhances the representation of local spatial variations, which is crucial for accurately rendering the complex patterns found in WSIs. Our experimental findings indicated a substantial improvement in the fidelity of histopathological image representation, as evidenced by a 3-6 dB increase in the peak signal-to-noise ratio compared to existing methods. This advancement underscores the potential of INRs to revolutionize digital histopathology, offering a pathway towards more efficient diagnostic imaging techniques. 
          </p>
        </div>
      </div>
    </div>
    
  </div>
</section>

<section class="section"></section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class=" is-centered ">
      <h2 class="title is-3 has-text-centered">CINR Model</h2>
      <hr>
      <h3 class="title">Position Encoding</h3>
      <img src="./static/images/enc-1.png">
      <p>
        Multi-resolution Hash Grid Encoding sets up L 2D grids across the domain, with each grid representing a different level of resolution. It encodes each grid point via a hash table of size T, where each index contains F trainable parameters (features), represented as a feature vector. 
      </p>
      <h3 class="title">Convolutional Implicit Neural Representation, CINR Model</h3>
      <img src="./static/images/model1-1.png">

      <p>
        The tensor position is processed using two parallel-network. The first flow, a standard MLP with two layers, focuses features of the target position, whereas the second flow, a CNN with and 3 Ã— 3 kernels, encompasses the features from the surrounding target position. The outputs from these two flows are merged and passed additional CNN layer to integrate the features, culminating in the of the target values.
      </p>
      <br>
      <hr>
      <br>

      <div class="columns is-centered" style="margin-bottom: 5%;">
        <div style="width: 40% " class="column">
          <img src="./static/images/model2-1.png">

        </div>
      
        <div class="column" style="width: 60%; vertical-align; middle;">
          <br>
          <h3 class="title is-4">Fully Connected Layer :</h3>
          <p>Directly maps coordinates to pixel values without spatial context. </p>
          <br>
          <h3 class="title is-4">Convolution Layer :</h3>
          <p>Uses convolution to capture spatial relationships between pixels, effectively representing high-frequency details.</p>
        </div>
      </div>
      
      
      
        </div>
    </div>
  </div>
</section>

<section class="hero teaser"></section>
  <div class="container is-max-desktop">
    <div class=" is-centered ">

      <h2 class="title is-3 has-text-centered">Result</h2>
      <hr>
      <h3 class="title is-4">Reconstructed Results - Qualitative evaluation</h3>
      <img src="./static/images/fig_diff_reboot2-1.png">
      
      <h3 class="title is-4">Reconstructed Results - Quantitative evaluation</h3>
      <img src="./static/images/fig3-eps-converted-to-1.png">

      <h3 class="title is-4">CINR based Image zoom in</h3>
      <class class="hero-body">
        <video id="teaser" autoplay muted loop playsinline height="100%">
          <source src="./static/videos/example17_.mp4"
                  type="video/mp4">
        </video>
        
        </class>
        </div>
    </div>
  </div>
</section>

<!-- 
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/example17_.mp4"
                    type="video/mp4">
          </video>
        </div>
        
      </div>
    </div>
  </div>
</section> -->




<!-- 
<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      <!-- <div class="column">
        <div class="content">
          <h2 class="title is-3">Visual Effects</h2>
          <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div> -->
      <!--/ Visual Effects. -->

      

  <!-- </div>
</section> --> 


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      <!-- @article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021}, -->
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a> -->
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            The website template was borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
